# AI-900: Microsoft Azure AI Fundamentals
- Describe Artificial Intelligence workloads and considerations (15–20%)
- Describe fundamental principles of machine learning on Azure (20–25%)
- Describe features of computer vision workloads on Azure (15–20%)
- Describe features of Natural Language Processing (NLP) workloads on Azure (15–20%)
- Describe features of generative AI workloads on Azure (15–20%)
- [Exam Study Guide](https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/ai-900)
- [Microsoft Azure Certification Program](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4J5ea)

## Artificial Intelligence on Microsoft Azure
- Azure Machine Learning Designer: a graphical interface that enables no-code development of machine learning solutions.
- Azure Anomaly Detector: anomaly detection is a machine learning-based technique that identifies unusual patterns in data sets.
- OCR: used to detect and read a text in images.
- Computer Vision is one of the Microsoft Azure Cognitive Services.
  - The CV service to analyze images and video
  - The Custom Vision service to train custom image classification and object detection models
  - The Face service for face detection and facial recognition
  - Semantic segmentation classifies individual pixels in images according to the objects they belong to.
- Language Understanding (LUIS) is a machine learning-based service used to build natural language into apps, bots, and IoT devices.
- QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer layer over your existing data.
- Form Recognizer can be used to extract information from structured documents, such as scanned forms and invoices.
- Conversational AI tools enable developers to build, connect, deploy, and manage intelligent bots that naturally interact with their users.
- Data mining workloads primarily focus on the searching and indexing of data.
- AI Software Development Principles:
  - Fairness: all AI systems treat all people fairly
  - Reliability and Safety: it requires an AI system to work alongside people in a physical environment by using AI controlled machinery. The system must function safely, while ensuring no harm will come to human life
  - Privacy and Security
  - Inclusiveness: AI should bring benefits to all parts of society, regardless of physical ability, gender, ethnicity, or other factors.
  - Transparency: users should be made fully aware of the purpose of the system, how it works and what limitations might be expected.
  - Accountability: ensure the solution meets ethical and legal standards that are clearly defined.

## Understand Responsible AI
- Fairness is meant to ensure that AI models do not unintentionally incorporate a bias based on criteria such as gender or ethnicity. The AI system must be designed to ensure that biased decision-making is avoided and not based on factors such as ethnicity and gender.
- The accountability principle ensures that AI systems are designed to meet any ethical and legal standards that are applicable. The privacy and security principle states that AI systems must be designed to protect any personal and/or sensitive data. The inclusiveness principle states that AI systems must empower people in a positive and engaging way. The fairness principle is applied to AI a system to ensure that users of the systems are treated fairly.
- The reliability and safety principles are of paramount importance here as it requires an AI system to work alongside people in a physical environment by using AI controlled machinery. The system must function safely, while ensuring no harm will come to human life.

## Natural Language Processing
- NLP is the area of AI that deals with creating software that understands written and spoken language.
- Vectorization captures semantic relationships between words by assigning them to locations in n-dimensional space. Lemmatization, also known as stemming, normalizes words before counting them. N-grams extend frequency analysis to include multi-term phrases.
- Removing stop words is the first in the statistical analysis of terms used in a text in the context of NLP:
  - Counting the occurrences of each takes place after stop words are removed.
  - Creating a vectorized model is not part of statistical analysis. It's used to capture the sematic relationship between words.
  - Encoding words as numeric features is not part of statistical analysis. It's frequently used in sentiment analysis.
- The Azure AI Speech service can be used to generate spoken audio from a text source for text-to-speech translation.
- The Universal Language Model used by the speech-to-text API is optimized for conversational and dictation scenarios. The acoustic, language, and pronunciation scenarios require developing your own model.
- The Azure AI Translator service supports text-to-text translation, but it does not support speech-to-text, text-to-speech, or speech-to-speech translation.
- Entity Linking, PII detection, and sentiment analysis are all elements of the Azure AI Service for Azure AI Language.
- Azure AI Vision deals with image processing. Azure AI Content Moderator is an Azure AI Services service used to check text, image, and video content for material that is potentially offensive.

## Fundamentals of Machine Learning
- Randomly split the data into rows for training and rows for evaluation
  - Datasets can be split into training datasets and validation datasets by splitting the data
- Multiple linear regression models a relationship between two or more features and a single label. Linear regression uses a single feature.
  - Features are used to generate predictions for the label, which is compared to the actual label value.
- Logistic regression is a type of classification model, which returns either a Boolean value or a categorical decision.
- Hierarchical clustering groups data points that have similar characteristics.
- Classification is used to predict categories of data. It can predict which category or class an item of data belongs to.
- The validation dataset is a sample of data held back from a training dataset. It is used to evaluate the performance of the trained model.
- A dataset is required to create automated machine learning (automated ML) run. A workspace must be created before you can access a Machine Learning studio.
- To deploy a predictive service from a newly trained model by using the ML designer, you must first create a pipeline in ML designer.
- You can deploy the best performing model for client applications to use over the internet by using an endpoint.
- The two components that can be dragged-and-dropped onto the canvas are datasets and modules.
  - Azure ML designer offers the possibility to save progress as a pipeline draft.
- Automated machine learning is the process of automating the time consuming, iterative tasks of machine learning model development